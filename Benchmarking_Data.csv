Index,Paper Title,Authors,Journal/Conference,Year,Tech (nm),Architecture,Cell Type,Core Size(Kb),N_row,N_col,Supply V(V),B_x,B_w,B_ADC,R_C,R,C_C,C,N_ADC,N,N_1b,B_pre-ADC,B_core,alpha,T_core(ns),CR(GB/s),TOPS,TOPS/W,E_OP1 (fJ),N_core,E_col (fJ),E_core (pJ),E_mvm (pJ),TOPS_a ,TOPS/mm2,Compute Model,IMC_Processor
23, A 28nm 384kb 6T-SRAM Computation-in-Memory Macro with 8b Precision for AI Edge Chips ,Jian-Wei Su et al.,ISSCC,2021,28,SRAM,6T,96,512,192,0.7,4,1,10,16,512,1,2,96,16,12288,8.0,6144.0,2,3.60,1706.67,3.41,1456,0.69,4,87.91,8.44,67.52,13.65,,QR,
23, A 28nm 384kb 6T-SRAM Computation-in-Memory Macro with 8b Precision for AI Edge Chips ,Jian-Wei Su et al.,ISSCC,2021,28,SRAM,6T,96,512,192,0.7,4,1,10,16,512,1,2,96,16,12288,8.0,6144.0,1,4.00,1536.00,3.07,1508.96,0.66,4,84.83,8.14,32.57,12.29,,QR,
24,A 2.75-to-75.9TOPS/W Computing-in-Memory NN Processor Supporting Set-Associate Block-Wise Zero Skipping and Ping-Pong CIM with Simultaneous Computation and Weight Updating,Jinshan Yue et al.,ISSCC ,2021,65,SRAM,6T,16,128,128,1,1,1,4,128,128,1,4,32,128,8192,7.0,4096.0,1,10.00,409.60,0.82,740,1.35,4,345.95,11.07,44.28,3.28,1.91,QS,Y
25,A Programmable Neural-Network Inference Accelerator Based on Scalable In-Memory Computing,Hongyang Jia et al.,ISSCC,2021,16,SRAM,8T1C,294,1152,256,0.8,1,1,8,1152,1152,1,1,256,1152,589824,10.2,294912.0,4,50.00,5898.24,11.80,1936,0.52,16,1190.08,304.66,19498.31,188.74,44.94,QR,Y
46,A 5.99-to-691.1TOPS/W Tensor-Train In-Memory-Computing Processor Using Bit-Level-Sparsity-Based Optimization and Variable-Precision Quantization,Ruiqi Guo et al.,ISSCC,2021,28,SRAM,6T,64,64,1024,0.6,2,1,5,64,64,1,16,128,64,32768,8.0,16384.0,1,,,0.005,383.68,2.606,16,333.611,42.702,683.236,0.087,0.03,QS,Y
46,A 5.99-to-691.1TOPS/W Tensor-Train In-Memory-Computing Processor Using Bit-Level-Sparsity-Based Optimization and Variable-Precision Quantization,Ruiqi Guo et al.,ISSCC,2021,28,SRAM,6T,64,64,1024,0.9,2,1,5,64,64,1,16,128,64,32768,8.0,16384.0,1,,,0.009,59.36,16.846,16,2156.334,276.011,4416.173,0.150,0.05,QS,Y
28,A 89 TOPS/W and 16.3 TOPS/mm2 All Digital SRAM- Based Full Precision Compute-In-Memory in 22nm for Machine-Learning Edge Applications,Yu-Der Chih et al.,ISSCC,2021,22,SRAM,6T+D,64,256,256,0.72,1,4,0,256,256,4,4,64,256,131072,12.0,65536.0,1,10.00,6553.60,13.11,1424,0.70,1,1438.20,92.04,92.04,13.11,64.89,DIMC,
33,"A 22 nm, 1540 TOP/s/W, 12.1 TOP/s/mm2 in-Memory Analog Matrix-Vector-Multiplier for DNN Acceleration",I. A. Papistas et al.,CICC,2021,22,SRAM,18T,1048,1024,1024,0.8,7,1.5,6,1024,1024,2,2,512,1024,11010048,18.5,5505024.0,1,44.40,123987.03,247.97,11025,0.09,1,1950.48,998.64,998.64,247.97,127.82,QS,
33,"A 22 nm, 1540 TOP/s/W, 12.1 TOP/s/mm2 in-Memory Analog Matrix-Vector-Multiplier for DNN Acceleration",I. A. Papistas et al.,CICC,2021,22,SRAM,18T,1048,1024,1024,0.6,7,1.5,6,1024,1024,2,2,512,1024,11010048,18.5,5505024.0,1,178.57,30828.38,61.66,19635,0.05,1,1095.19,560.74,560.74,61.66,31.78,QS,
34,A 128x128 SRAM Macro with Embedded Matrix-Vector Multiplication Exploiting Passive Gain via MOS Capacitor for Machine Learning Application,Rezwan A Rasul et al.,CICC,2021,65,SRAM,20T1C,16,128,128,0.7,5,1.5,5,128,128,2,2,64,128,122880,13.5,61440.0,1,325.00,189.05,0.38,2482.5,0.40,1,773.41,49.50,49.50,0.38,0.36,QR,
35,Fully Row/Column-Parallel In-memory Computing SRAM Macro employing Capacitor-based Mixed-signal Computation with 5-b Inputs,Jinseok Lee et al.,VLSI Circuits,2021,28,SRAM,10T1C,288,1156,256,0.9,5,1,8,1152,1152,1,1,256,1152,2949120,15.2,1474560.0,1,480.00,3072.00,6.14,5796,0.17,1,1987.58,508.82,508.82,6.14,12.05,QR,
36,PIMCA: A 3.4-Mb Programmable In-Memory Computing Accelerator in 28nm for On-Chip DNN Inference,Shihui Yin et al.,VLSI Circuits,2021,28,SRAM,10T1C,32,256,128,1,1,1,4,256,256,1,1,128,256,65536,8.0,32768.0,1,,,0.05,588,1.70,108,870.75,111.46,12037.22,4.90,0.35,QR,Y
37,A 6.54-to-26.03 TOPS/W Computing-In-Memory RNN Processor using Input Similarity Optimization and Attention-based Context-breaking with Output Speculation,Ruiqi Guo et al.,VLSI Circuits,2021,65,SRAM,6T,4,64,64,0.75,1,1,3,8,64,1,1,64,8,1024,3.0,512.0,2,6.25,81.92,0.16,52.06,19.21,16,307.34,19.67,629.43,2.62,1.02,IS,Y
37,A 6.54-to-26.03 TOPS/W Computing-In-Memory RNN Processor using Input Similarity Optimization and Attention-based Context-breaking with Output Speculation,Ruiqi Guo et al.,VLSI Circuits,2021,65,SRAM,6T,4,64,64,1.1,1,1,3,8,64,1,1,64,8,1024,3.0,512.0,2,3.31,154.68,0.31,,,16,,,,4.95,1.93,IS,Y
1,A 28nm 64Kb Inference-Training Two-Way Transpose Multibit 6T SRAM Compute-in-Memory Macro for AI Edge Chips,Jian-Wei Su et al.,ISSCC,2020,28,SRAM,6T,64,512,128,0.85,2,1,5,16,512,1,1,128,16,8192,6.0,4096.0,2,4.30,952.56,1.91,972.8,1.03,1,65.79,8.42,16.84,1.91,,QS,
1,A 28nm 64Kb Inference-Training Two-Way Transpose Multibit 6T SRAM Compute-in-Memory Macro for AI Edge Chips,Jian-Wei Su et al.,ISSCC,2020,28,SRAM,6T,64,128,512,0.85,2,1,5,16,128,1,2,256,16,16384,6.0,8192.0,4,5.25,1560.38,3.12,960,1.04,1,66.67,17.07,68.27,3.12,,QS,
2,A 351TOPS/W and 372.4GOPS Compute-in-Memory SRAM Macro in 7nm FinFET CMOS for Machine-Learning Applications,Qing Dong et al.,ISSCC,2020,7,SRAM,8T,4,64,64,0.8,4,4,4,64,64,4,4,16,64,32768,14.0,16384.0,1,5.50,2978.91,5.96,5616,0.18,1,364.67,5.83,5.83,5.96,1861.82,QS-QR,
2,A 351TOPS/W and 372.4GOPS Compute-in-Memory SRAM Macro in 7nm FinFET CMOS for Machine-Learning Applications,Qing Dong et al.,ISSCC,2020,7,SRAM,8T,4,64,64,1,4,4,4,64,64,4,4,16,64,32768,14.0,16384.0,1,4.50,3640.89,7.28,5136,0.19,1,398.75,6.38,6.38,7.28,2275.56,QS-QR,
53,A 65nm Computing-in-Memory-Based CNN Processor with 2.9-to-35.8TOPS/W System Energy Efficiency Using Dynamic-Sparsity Performance-Scaling Architecture and Energy-Efficient Inter/Intra-Macro Data Reuse,Jinshan Yue et al.,ISSCC,2020,65,SRAM,8T,4,64,64,1,2,4,5,16,64,4,4,16,16,4096,10.0,2048.0,1,,,0.03,1270.40,0.787,4,100.756,1.612,6.448,0.135,0.23,QS,Y
53,A 65nm Computing-in-Memory-Based CNN Processor with 2.9-to-35.8TOPS/W System Energy Efficiency Using Dynamic-Sparsity Performance-Scaling Architecture and Energy-Efficient Inter/Intra-Macro Data Reuse,Jinshan Yue et al.,ISSCC,2020,65,SRAM,8T,4,64,64,1,2,4,5,16,64,4,4,16,16,4096,10.0,2048.0,2,,,0.14,504.96,1.980,4,253.485,4.056,32.446,0.580,0.98,QS,Y
3,A 16K Current-Based 8T SRAM Compute-In-Memory Macro with Decoupled Read/Write and 1-5bit Column ADC,Chengshuo Yu et al.,CICC,2020,65,SRAM,8T,16,128,128,0.45,1,1,1,64,128,1,1,128,64,16384,6.0,8192.0,1,5.00,1638.40,3.28,490,2.04,1,261.22,33.44,33.44,3.28,59.80,QS,
3,A 16K Current-Based 8T SRAM Compute-In-Memory Macro with Decoupled Read/Write and 1-5bit Column ADC,Chengshuo Yu et al.,CICC,2020,65,SRAM,8T,16,128,128,0.45,1,1,5,64,128,1,1,128,64,16384,6.0,8192.0,1,155.00,52.85,0.11,15.8,63.29,1,8101.27,1036.96,1036.96,0.11,1.93,QS,
4,A 28nm 64Kb 6T SRAM Computing-in-Memory Macro with 8b MAC Operation for AI Edge Chips,Xin Si et al.,ISSCC ,2020,28,SRAM,6T,64,512,128,0.85,2,1,6,16,64,1,16,128,16,8192,6.0,4096.0,1,4.20,975.24,1.95,1488.64,0.67,1,42.99,5.50,5.50,1.95,7.23,QS,
5,A Programmable Heterogeneous Microprocessor Based on Bit-Scalable In-Memory Computing,Hongyang Jia et al.,JSSC ,2020,65,SRAM,8T1C,590,2304,256,1.2,1,1,8,2304,2304,1,1,256,2304,1179648,11.2,589824.0,8,700.00,842.61,1.69,192,5.21,1,24000.00,6144.00,49152.00,1.69,0.46,QR,Y
5,A Programmable Heterogeneous Microprocessor Based on Bit-Scalable In-Memory Computing,Hongyang Jia et al.,JSSC ,2020,65,SRAM,8T1C,590,2304,256,0.85,1,1,8,2304,2304,1,1,256,2304,1179648,11.2,589824.0,8,1750.00,337.04,0.67,400,2.50,1,11520.00,2949.12,23592.96,0.67,0.19,QR,Y
6,C3SRAM: An In-Memory-Computing SRAM Macro Based on Robust Capacitive Coupling Computing Mechanism,Zhewei Jiang et al.,JSSC,2020,65,SRAM,8T1C,16,256,64,1,1,1,3.4,256,256,1,1,64,256,32768,8.0,16384.0,1,20.00,819.20,1.64,671.5,1.49,1,762.47,48.80,48.80,1.64,20.23,QR,
7,A Twin-8T SRAM Computation-In-Memory Macro for Multiple-Bit CNN-Based Machine Learning,Xin Si et al.,ISSCC,2019,55,SRAM,16T,3.8,64,60,1,2,5,5,27,64,5,5,8,27,4320,11.8,2160.0,1,5.00,432.00,0.86,750,1.33,1,720.00,5.76,5.76,0.86,23.35,QS-QR,
7,A Twin-8T SRAM Computation-In-Memory Macro for Multiple-Bit CNN-Based Machine Learning,Xin Si et al.,ISSCC,2019,55,SRAM,16T,3.8,64,60,1,2,5,5,64,64,5,5,8,64,10240,13.0,5120.0,1,5.00,1024.00,2.05,907.2,1.10,1,1410.93,11.29,11.29,2.05,55.35,QS-QR,
8,A 5.1pJ/Neuron 127.3us/Inference RNN-based Speech Recognition Processor using 16 Computing-in-Memory SRAM Macros in 65nm CMOS,Ruiqi Guo et al.,VLSI,2019,65,SRAM,6T,4,64,64,0.9,1,1,3,4,64,1,1,64,4,512,2.0,256.0,1,6.70,38.21,0.08,23.4,42.74,16,341.88,21.88,350.09,1.22,0.20,QS,Y
9,An SRAM-Based Accelerator for Solving Partial Differential Equations,Thomas Chen et al.,CICC,2019,180,SRAM,8T,20,320,64,1.8,5,5,5,10,320,2,2,32,4,6400,12.0,3200.0,1,90.00,35.56,0.07,21.425,46.67,4,9334.89,298.72,1194.87,0.28,0.15,QS,
10,Sandwich-RAM: An Energy-Efficient In-Memory BWN Architecture with Pulse-Width Modulation,Jun Yang et al.,ISSCC,2019,28,SRAM,8T,150,,,0.6,8,1,5,,,,,1,363,5808,16.5,2904.0,1,2.50,1161.60,2.32,1915.2,0.52,1,3032.58,3.03,3.03,2.32,10.75,,
10,Sandwich-RAM: An Energy-Efficient In-Memory BWN Architecture with Pulse-Width Modulation,Jun Yang et al.,ISSCC,2019,28,SRAM,8T,150,,,0.6,8,1,5,,,,,1,576,9216,17.2,4608.0,1,2.50,1843.20,3.69,1915.2,0.52,1,4812.03,4.81,4.81,3.69,17.05,,
11,Area-Efficient and Variation-Tolerant In-Memory BNN Computing using 6T SRAM Array,Jinseok Kim et al.,VLSI,2019,28,SRAM,6T,16,256,64,1,1,1,1,192,256,1,1,64,192,24576,7.6,12288.0,1,40.00,307.20,0.61,300,3.33,1,1280.00,81.92,81.92,0.61,65.36,IS,
12,A 65nm 4Kb Algorithm-Dependent Computing-in-Memory SRAM Unit- Macro with 2.3ns and 55.8TOPS/W Fully Parallel Product-Sum Operation for Binary DNN Edge Processors,Win-San Khwa et al.,ISSCC,2018,65,SRAM,6T,4,64,64,0.725,1,1,1,64,64,1,1,64,64,8192,6.0,4096.0,1,2.30,1780.87,3.56,111.6,8.96,2,1146.95,73.41,146.81,7.12,,IS,
13,A 42pJ/Decision 3.12TOPS/W Robust In-Memory Machine Learning Classifier with On-Chip Training,Sujan Kumar Gonugondla et al.,ISSCC,2018,65,SRAM,6T,16,512,256,1,8,8,6,4,512,256,256,1,128,16384,23.0,8192.0,1,31.25,262.14,0.52,400,2.50,1,40960.00,40.96,40.96,0.52,0.65,QS-QR,
14,"A Ternary Based Bit Scalable, 8.80 TOPS/W CNN accelerator with Many-core Processing-in-memory Architecture with 896K synapses/mm2",Shunsuke Okumura et al.,VLSI,2019,12,SRAM,17T,9.47,148,32,0.72,1,1.5,1,148,148,1,1,32,148,14208,8.7,7104.0,1,10.00,710.40,1.42,634.4,1.58,512,699.87,22.40,11466.73,727.45,80.83,IS,Y
15,Conv-RAM: An Energy-Efficient SRAM with Embedded Convolution Computation for Low-Power CNN-Based Machine Learning Applications,Avishek Biswas et al.,ISSCC,2018,65,SRAM,10T,16,64,256,1.2,7,1,7,50,64,1,16,16,50,11200,12.6,5600.0,1,150.00,37.33,0.07,196.7,5.08,1,3558.72,56.94,56.94,0.07,1.11,QR,
16,A Mixed-Signal Binarized Convolutional-Neural-Network Accelerator Integrating Dense Weight Storage and Multiplication for Reduced Data Movement,Hossein Valavi et al.,VLSI Tech,2018,65,SRAM,8T1C,2360,1536,1536,0.94,1,3,1,1536,1536,3,3,512,1536,4718592,13.6,2359296.0,1,250.00,9437.18,18.87,866,1.15,1,10642.03,5448.72,5448.72,18.87,1.50,QR,
17,XNOR-SRAM: In-Memory Computing SRAM Macro for Binary/Ternary Deep Neural Networks ,Zhewei Jiang et al.,VLSI Tech,2018,65,SRAM,12T,16,256,64,1,1,1,3.46,256,256,1,64,1,256,512,8.0,256.0,1,0.85,302.24,0.60,139.1,7.19,1,3680.81,3.68,3.68,0.60,5.50,IS,
17,XNOR-SRAM: In-Memory Computing SRAM Macro for Binary/Ternary Deep Neural Networks ,Zhewei Jiang et al.,VLSI Tech,2018,65,SRAM,12T,16,256,64,0.6,1,1,3.46,256,256,1,64,1,256,512,8.0,256.0,1,2.50,102.40,0.20,403,2.48,1,1270.47,1.27,1.27,0.20,1.86,IS,
38,A Maximally Row-Parallel MRAM In-Memory-Computing Macro Addressing Readout Circuit Sensitivity and Area,Peter Deaville et al.,ESSCRIC,2021,22,eNVM,MRAM+Par,128,256,512,0.8,1,1,4,128,256,1,4,128,128,32768,7.0,16384.0,1,315.80,51.88,0.10,5.1,196.08,1,50196.08,6425.10,6425.10,0.10,0.76,IS,
29,A 22nm 4Mb 8b-Precision ReRAM Computing-in-Memory Macro with 11.91-195.7 TOPS/W for Tiny AI Edge Devices,Cheng-Xin Xue et al.,ISSCC,2021,22,eNVM,ReRAM+Par,524,1024,512,0.8,1,1,4,4,1024,1,8,64,4,512,2.0,256.0,1,4.90,52.24,0.10,395,2.53,8,20.25,1.30,10.37,0.84,0.32,IS,
29,A 22nm 4Mb 8b-Precision ReRAM Computing-in-Memory Macro with 11.91-195.7 TOPS/W for Tiny AI Edge Devices,Cheng-Xin Xue et al.,ISSCC,2021,22,eNVM,ReRAM+Par,524,1024,512,0.8,4,1,4,4,1024,1,8,64,4,2048,6.0,1024.0,1,10.30,99.42,0.20,756.16,1.32,8,42.32,2.71,21.67,1.59,0.60,IS,
29,A 22nm 4Mb 8b-Precision ReRAM Computing-in-Memory Macro with 11.91-195.7 TOPS/W for Tiny AI Edge Devices,Cheng-Xin Xue et al.,ISSCC,2021,22,eNVM,ReRAM+Par,524,1024,512,0.8,8,1,4,4,1024,1,8,64,4,4096,10.0,2048.0,1,14.80,138.38,0.28,762.24,1.31,8,83.96,5.37,42.99,2.21,0.84,IS,
49,HERMES Core – A 14nm CMOS and PCM-based In-Memory Compute Core using an array of 300ps/LSB Linearized CCO-based ADCs and local digital processing,R. Khaddam-Aljameh et al.,VLSI Circuits,2021,14,eNVM,PCM+cross,262,256,256,0.8,8,4,12,256,256,1,1,256,256,4194304,20.0,2097152.0,1,130.00,16131.94,32.26,336.00,2.976,1,48761.905,12483.048,97.524,32.264,50.88,IS,
51,"Secure-RRAM: A 40nm 16kb Compute-in-Memory Macro with Reconfigurability, Sparsity Control, and Embedded Security",Wantong Li et al.,CICC,2021,40,eNVM,ReRAM+par,16,128,128,0.9,1,1,3,7,128,1,8,8,7,112,2.8,56.0,1,70.00,0.80,0.0016,8.48,117.925,1,1650.943,13.208,13.208,0.002,0.032,IS,
41,"A 40-nm, 64-Kb, 56.67 TOPS/W Voltage-Sensing Computing-In-Memory/Digital RRAM Macro Supporting Iterative Write With Verification and Online Read-Disturb Detection",Jong-Hyeok Yoon et al.,JSSC,2021,40,eNVM,ReRAM+Par,64,256,256,0.9,1,1,4,9,256,1,8,8,9,144,3.2,72.0,1,10.00,7.20,0.01,56.67,17.65,1,317.63,2.54,2.54,0.01,0.01,IS,
30,A Fully Integrated Analog ReRAM Based 78.4TOPS/W Compute-In-Memory Chip with Fully Parallel MAC Computing,Qi Liu et al.,ISSCC,2020,130,eNVM,ReRAM+Cross,158.8,1024,100,4.2,1,1.5,1,784,784,1,1,100,784,235200,11.1,117600.0,1,51.10,2301.37,4.60,117.6,8.50,1,20000.00,2000.00,2000.00,4.60,0.45,IS,
31,A 22nm 2Mb ReRAM Compute-in-Memory Macro with 121-28TOPS/W for Multibit MAC Computing for Tiny AI Edge Devices,Cheng-Xin Xue et al.,ISSCC,2020,22,eNVM,ReRAM+Par,262,512,512,0.8,1,2,6,1,512,2,32,16,1,64,2.0,32.0,1,9.80,3.27,0.01,242.76,4.12,8,16.48,0.26,2.11,0.05,0.03,IS,
31,A 22nm 2Mb ReRAM Compute-in-Memory Macro with 121-28TOPS/W for Multibit MAC Computing for Tiny AI Edge Devices,Cheng-Xin Xue et al.,ISSCC,2020,22,eNVM,ReRAM+Par,262,512,512,0.8,2,4,6,1,512,4,32,16,1,256,6.0,128.0,1,13.10,9.77,0.02,364.16,2.75,8,43.94,0.70,5.62,0.16,0.08,IS,
31,A 22nm 2Mb ReRAM Compute-in-Memory Macro with 121-28TOPS/W for Multibit MAC Computing for Tiny AI Edge Devices,Cheng-Xin Xue et al.,ISSCC,2020,22,eNVM,ReRAM+Par,262,512,512,0.8,4,4,6,1,512,4,32,16,1,512,8.0,256.0,1,18.30,13.99,0.03,462.88,2.16,8,69.13,1.11,8.85,0.22,0.11,IS,
57,Embedded 1-Mb ReRAM-Based Computing-in-Memory Macro With Multibit Input and Weight for CNN-Based AI Edge Processors,Cheng-Xin Xue et al.,JSSC,2019,55,eNVM,ReRAM+Par,131,256,512,1,1,3,4,9,256,1,128,4,9,216,6.2,108.0,1,11.75,9.19,0.02,159.51,6.27,8,338.54,1.35,10.83,0.15,0.02,IS,
57,Embedded 1-Mb ReRAM-Based Computing-in-Memory Macro With Multibit Input and Weight for CNN-Based AI Edge Processors,Cheng-Xin Xue et al.,JSSC,2019,55,eNVM,ReRAM+Par,131,256,512,1,2,3,4,9,256,1,128,4,9,432,8.2,216.0,1,14.60,14.79,0.03,131.4,7.61,8,821.92,3.29,26.30,0.24,0.03,IS,
40,High-Throughput In-Memory Computing for Binary Deep Neural Networks With Monolithically Integrated RRAM and 90-nm CMOS,Shihui Yin et al.,TED,2020,90,eNVM,ReRAM+Par,8,128,64,1.2,1,1,3,128,128,1,8,8,64,1024,6.0,512.0,1,6.50,78.77,0.16,24.1,41.49,1,5311.20,42.49,42.49,0.16,3.46,IS,
39,A 4M Synapses integrated Analog ReRAM based 66.5 TOPS/W Neural-Network Processor with Cell Current Controlled Writing and Flexible Network Architecture,Reiji Mochida et al.,VLSI,2018,180,eNVM,ReRAM+Par,2000,,,1.8,1,8,1,196,,,,16,196,50176,15.6,25088.0,1,19.18,1308.03,2.62,165.6,6.04,1,18937.20,303.00,303.00,2.62,0.21,IS,
39,A 4M Synapses integrated Analog ReRAM based 66.5 TOPS/W Neural-Network Processor with Cell Current Controlled Writing and Flexible Network Architecture,Reiji Mochida et al.,VLSI,2018,40,eNVM,ReRAM+Par,4000,,,1.1,1,8,1,196,,,,16,196,50176,15.6,25088.0,1,9.56,2624.27,5.25,532,1.88,1,5894.74,94.32,94.32,5.25,1.94,IS,
44,eDRAM-CIM: Compute-In-Memory Design with Reconfigurable Embedded-Dynamic-Memory Array Realizing Adaptive Data Converters and Charge-Domain Computing,Shanshan Xie et al.,ISSCC,2021,65,eDRAM ,1T1C,16,,,1.1,8,8,8,1,,,,,,,,,2,,,0.30,304.64,3.283,1,,,,0.301,0.53,QR,
45,"A 65nm 3T Dynamic Analog RAM-Based Computing-in- Memory Macro and CNN Accelerator with Retention Enhancement, Adaptive Analog Sparsity and 44TOPS/W System Energy Efficiency",Zhengyu Chen et al.,ISSCC,2021,65,eDRAM ,3T,8,64,32,1,4,4,5,64,32,1,1,32,64,65536,14.0,32768.0,1,9.52,3442.02,6.88,1635.20,0.612,4,1252.446,40.078,160.313,27.536,134.98,QS,Y
26,"A 7nm 4-Core AI Chip with 25.6TFLOPS Hybrid FP8 Training, 102.4TOPS INT4 Inference and Workload-Aware Throttling",Ankur Agarwal et al.,ISSCC,2021,7,Digital,Digital,8000,,,0.75 (Digital); 0.95 (SRAM),8,8,,,,,,,,,,,,,,409.6,83.84,11.93,,,,,,83.59,,
26,"A 7nm 4-Core AI Chip with 25.6TFLOPS Hybrid FP8 Training, 102.4TOPS INT4 Inference and Workload-Aware Throttling",Ankur Agarwal et al.,ISSCC,2021,7,Digital,Digital,8000,,,0.75 (Digital); 0.95 (SRAM),4,4,,,,,,,,,,,,,,409.6,83.52,11.97,,,,,,83.59,,
27,A 6K-MAC Feature-Map-Sparsity-Aware Neural Processing Unit in 5nm Flagship Mobile SoC,Jun-Seok Park et al.,ISSCC,2021,5,Digital,Digital,8192,,,0.6,8,8,,,,,,,,,,,,,,313.6,870.4,1.15,3,,,,,172.31,,
42,A 28nm 12.1TOPS/W Dual-Mode CNN Processor Using Effective-Weight-Based Convolution and Error-Compensation-Based Prediction,Huiyu Mo et al.,ISSCC,2021,28,Digital,Digital,1648,,,0.9,8,8,,,,,,,,,,,,,,101.89,774.40,1.291,1,,,,101.888,53.63,,
42,A 28nm 12.1TOPS/W Dual-Mode CNN Processor Using Effective-Weight-Based Convolution and Error-Compensation-Based Prediction,Huiyu Mo et al.,ISSCC,2021,28,Digital,Digital,1648,,,0.6,8,8,,,,,,,,,,,,,,21.70,1120.00,0.893,1,,,,21.696,11.42,,
43,A 40nm 4.81TFLOPS/W 8b Floating-Point Training Processor for Non-Sparse Neural Networks Using Shared Exponent Bias and 24-Way Fused Multiply-Add Tree,Jeongwoo Park et al.,ISSCC,2021,40,Digital,Digital,2344,,,1.1,8,8,,,,,,,,,,,,,,36.29,157.44,6.352,1,,,,36.288,5.81,,
43,A 40nm 4.81TFLOPS/W 8b Floating-Point Training Processor for Non-Sparse Neural Networks Using Shared Exponent Bias and 24-Way Fused Multiply-Add Tree,Jeongwoo Park et al.,ISSCC,2021,40,Digital,Digital,2344,,,0.75,8,8,,,,,,,,,,,,,,4.03,307.84,3.248,1,,,,4.032,0.65,,
50,A 13.7 TFLOPS/W Floating-point DNN Processor using Heterogeneous Computing Architecture with Exponent-Computing-in-Memory,Juhyoung Lee et al.,VLSI Circuits,2021,28,Digital,6T,80,512,128,0.76,16,16,,,,,,,,,,,,,,1.91,366.08,2.732,16,,,,30.566,5.241,,
52,A 400MHz NPU with 7.8TOPS2/W High-Performance- Guaranteed Efficiency in 55nm for Multi-Mode Pruning and Diverse Quantization Using Pattern-Kernel Encoding and Reconfigurable MAC Unit,Zhanhong Tan et al.,CICC,2021,55,Digital,Digital,121.50,,,1,8,4,,,,,,,,,,,,,,2.81,211.68,4.724,16,,,,45.030,3.30,,
18,GANPU: A 135TFLOPS/W Multi-DNN Training Processor for GANs with Speculative Dual-Sparsity Exploitation,Sanghoon Kang et al.,ISSCC,2020,65,Digital,Digital,5408,,,0.75,16,16,,,,,,,,,,,,20.00,,,463.36,2.16,,,,,,,,
18,GANPU: A 135TFLOPS/W Multi-DNN Training Processor for GANs with Speculative Dual-Sparsity Exploitation,Sanghoon Kang et al.,ISSCC,2020,65,Digital,Digital,5408,,,1.1,16,16,,,,,,,,691200,,,,5.00,,138.24,212.48,4.71,,,,,,4.267,,
19,A 12nm Programmable Convolution-Efficient Neural-Processing-Unit Chip Achieving 825TOPS,Yang Jiao et al.,ISSCC,2020,12,Digital,Digital,1536000,,,,8,8,,,,,,,,18744000,,,,1.42,,13200.00,188.16,5.31,,,,,,74.47,,
20,A 3.4-to-13.3TOPS/W 3.6TOPS Dual-Core Deep-Learning Accelerator for Versatile AI Applications in 7nm 5G Smartphone SoC,Chien-Hung Lin et al.,ISSCC,2020,7,Digital,Digital,17408,,,0.575,8,8,,,,,,,,262025.216,,,,1.14,,230.66,218.88,4.57,,,,,,75.87,,
54,A 3.0 TFLOPS 0.62V Scalable Processor Core for High Compute Utilization AI Training and Inference,Jinwook Oh et al.,VLSI Tech,2020,14,Digital,Digital,16000,,,0.62,16,16,,,,,,,,,,,,,,768.00,281.60,3.551,1,,,,768.000,78.02,,
54,A 3.0 TFLOPS 0.62V Scalable Processor Core for High Compute Utilization AI Training and Inference,Jinwook Oh et al.,VLSI Tech,2020,14,Digital,Digital,16000,,,0.54,16,16,,,,,,,,,,,,,,512.00,358.40,2.790,1,,,,512.000,52.01,,
55,Z-PIM: An Energy-Efficient Sparsity Aware Processing-In-Memory Architecture with Fully-Variable Weight Precision,Ji-Hoon Kim et al.,VLSI Circuits,2020,65,Digital,8T,38,256,128,1,16,16,,,,,,,,,,,,,,101.84,79.36,12.601,8,,,,814.72,270.85,,
56,A Compute SRAM with Bit-Serial Integer/Floating-Point Operations for Programmable In-Memory Vector Acceleration,Jingcheng Wang et al.,ISSCC,2019,28,Digital,8T,128,128,256,0.6,8,8,,,,,,,,,,,,,,0.23,35.84,27.902,8,,,,1.874,1.56,,
56,A Compute SRAM with Bit-Serial Integer/Floating-Point Operations for Programmable In-Memory Vector Acceleration,Jingcheng Wang et al.,ISSCC,2019,28,Digital,8T,128,128,256,0.6,8,8,,,,,,,,,,,,,,0.02,337.28,2.965,8,,,,0.144,0.12,,
58,"A 0.11 pJ/Op, 0.32-128 TOPS, Scalable Multi-Chip-Module-based Deep Neural Network Accelerator with Ground-Reference Signaling in 16nm",Brian Zimmer et al.,VLSI Circuits,2019,16,Digital,Digital,5000,,,0.41,8,8,,,,,,,,131072,,,1,6.20,,20.48,608.00,1.645,1,,,,20.480,6.61,,
60,"A 40-nm, 2M-Cell, 8b-Precision, Hybrid SLC-MLC PCM Computing-in-Memory Macro with 20.5 - 65.0TOPS/W for Tiny-AI Edge Devices",Win-San Khwa et al.,ISSCC,2022,40,eNVM,PCM+Par,262,256,1024,0.85,1,1.6,4,8,256,1,8,130,8,3328,4.6,1664.0,8,2.21,752.09,1.50,1312,0.76,8,19.51,2.54,162.34,12.03,0.67,IS,
61,An 8-Mb DC-Current-Free Binary-to-8b Precision ReRAM Nonvolatile Computing-in-Memory Macro using Time-Space- Readout with 1286.4 - 21.6TOPS/W for Edge-AI Devices,Je-Min Hung et al.,ISSCC,2022,22,eNVM,ReRAM+Par,256,1024,256,0.8,1,1,3,8,1024,1,8,32,8,512,3.0,256.0,8,1.80,142.22,0.28,1382.4,0.72,32,11.57,0.37,94.81,9.10,0.51,QS,
62,"A 28nm 1Mb Time-Domain Computing-in-Memory 6T-SRAM Macro with a 6.6ns Latency, 1241GOPS and 37.01TOPS/W for 8b-MAC Operations for Edge-AI Devices",Ping-Chun Wu et al.,ISSCC,2022,28,SRAM,6T,131,1024,128,0.9,2,1,7,64,128,1,16,256,64,65536,8.0,32768.0,1,6.6,4964.85,9.93,1776,0.56,8,144.14,36.90,295.21,79.44,199.67,,
63,A 5-nm 254-TOPS/W 221-TOPS/mm2 Fully-Digital Computing- in-Memory Macro Supporting Wide-Range Dynamic-Voltage- Frequency Scaling and Simultaneous MAC and Write Operations,Hidehiro Fujiwara et al.,ISSCC,2022,5,SRAM,12T+D,64,256,256,0.9,4,4,,256,256,256,64,64,64,131072,14.0,65536.0,1,3.45,18995.94,37.99,1118.4,0.89,8,1831.19,117.20,937.57,303.94,2922.45,DIMC,
63,A 5-nm 254-TOPS/W 221-TOPS/mm2 Fully-Digital Computing- in-Memory Macro Supporting Wide-Range Dynamic-Voltage- Frequency Scaling and Simultaneous MAC and Write Operations,Hidehiro Fujiwara et al.,ISSCC,2022,5,SRAM,12T+D,64,256,256,0.5,4,4,,256,256,256,64,64,64,131072,14.0,65536.0,1,13.85,4731.84,9.46,4056,0.25,8,504.93,32.32,258.52,75.71,727.98,DIMC,
64,A 1.041-Mb/mm2 27.38-TOPS/W Signed-INT8 Dynamic-Logic- Based ADC-less SRAM Compute-In-Memory Macro in 28nm with Reconfigurable Bitwise Operation for AI and Embedded Applications,Bonan Yan et al.,ISSCC,2022,28,SRAM,6T,1,16,64,0.8,1,8,,1,16,16,64,1,64,1024,14.0,512.0,8,3,170.67,0.34,1752.32,0.57,1,584.37,0.58,4.67,0.34,11.38,DIMC,
65,A Multi-Mode 8K-MAC HW-Utilization-Aware Neural Processing Unit with a Unified Multi-Precision Datapath in 4nm Flagship Mobile SoC,Jun-Seok Park et al.,ISSCC,2022,4,Digital,Digital,1024,,,0.55,16,16,,,,,,,,,,,,,,1254.40,1090.56,0.92,2,,,,2508.80,440.32,,
66,"A 65nm Systolic Neural CPU Processor for Combined Deep Learning and General-Purpose Computing with 95% PE Utilization, High Data Locality and Enhanced End-to-End Performance",Yuhao Ju et al.,ISSCC,2022,65,Digital,Digital,150,,,1,8,8,,,,,,,,,,,,,,4.86,42.24,23.674,1,,,,4.864,1.09,,
67,COMB-MCM: Computing-on-Memory-Boundary NN Processor with Bipolar Bitwise Sparsity Optimization for Scalable Multi-Chiplet-Module Edge Machine Learning,Haozhe Zhu et al.,ISSCC,2022,65,Digital,8T,36,,,0.71,3,3,,,,,,,,,,,,,,0.07,126.90,7.880,32,,,,2.250,0.20,,
67,COMB-MCM: Computing-on-Memory-Boundary NN Processor with Bipolar Bitwise Sparsity Optimization for Scalable Multi-Chiplet-Module Edge Machine Learning,Haozhe Zhu et al.,ISSCC,2022,28,Digital,8T,54,432,128,0.63,4,3,,,,,,,,,,,,,,0.36,548.40,1.823,32,,,,11.640,1.34,,
68,Hiddenite: 4K-PE Hidden Network Inference 4D-Tensor Engine Exploiting On-Chip Model Construction Achieving 34.8-to-16.0TOPS/W for CIFAR-100 and ImageNet,Kazutoshi Hirose et al.,ISSCC,2022,40,Digital,Digital,8375,,,1.1,8,1,,,,,,,,,,,,,,40.08,124.00,8.065,1,,,,40.080,9.19,,
69,A 28nm 29.2TFLOPS/W BF16 and 36.5TOPS/W INT8 Reconfigurable Digital CIM Processor with Unified FP/INT Pipeline and Bitwise In-Memory Booth Multiplication for Cloud Deep Learning Acceleration,Fengbin Tu et al.,ISSCC,2022,28,SRAM,6T+D,6,128,48,1,2,8,,,,,,96,8,24576,13.0,12288.0,1,4.55,2700.66,5.40,1244.80,0.803,16,205.656,19.743,315.887,86.421,5.74,DIMC,Y
70,DIANA: An End-to-End Energy-Efficient DIgital and ANAlog Hybrid Neural Network SoC,Kodai Ueyoshi et al.,ISSCC,2022,22,Digital,Digital,6656,,,0.55,8,8,,,,,,,,,,,,,,8.96,262.4,3.81,1,,,,8.96,1.36,,
70,DIANA: An End-to-End Energy-Efficient DIgital and ANAlog Hybrid Neural Network SoC,Kodai Ueyoshi et al.,ISSCC,2022,22,SRAM,18T,1172,1152,1024,0.55,7,1.5,6,576,1152,2,2,512,512,5505024,17.5,2752512.0,1,17.6,417047.27,312.79,6300,0.16,1,1706.67,873.81,873.81,312.79,136.59,QS,Y
72,Analog Matrix Processor for Edge AI Real-Time Video Analytics ,Laura Fick et al.,ISSCC,2022,40,eNVM,NOR-F,2097,1024,2048,,1,8,8,1024,1024,1,8,256,1024,4194304,18.0,2097152.0,1,,,13.98,332.80,3.005,76,49230.769,12603.077,957833.846,1062.400,5.60,IS,Y
73,DIMC: 2219TOPS/W 2569F2/b Digital In-Memory Computing Macro in 28nm Based on Approximate Arithmetic Hardware,Dewei Wang et al.,ISSCC,2022,28,SRAM,8T+D,16,256,64,0.9,1,1,,256,,64,,,256,32768,8.0,16384.0,1,3.58,4576.54,9.15,1108.00,0.903,1,462.094,29.574,29.574,9.153,277.37,DIMC,
73,DIMC: 2219TOPS/W 2569F2/b Digital In-Memory Computing Macro in 28nm Based on Approximate Arithmetic Hardware,Dewei Wang et al.,ISSCC,2022,28,SRAM,8T+D,16,256,64,0.9,1,1,,256,,64,,,256,32768,8.0,16384.0,1,4.00,4096.00,8.19,616.00,1.623,1,831.169,53.195,53.195,8.192,167.18,DIMC,
74,A 40nm 64kb 26.56TOPS/W 2.37Mb/mm2 RRAM Binary/Compute-in-Memory Macro with 4.23× Improvement in Density and >75% Use of Sensing Dynamic Range,Samuel D. Spetalnick et al.,ISSCC,2022,40,eNVM,ReRAM+Par,64,256,256,0.83,1,1,4,9,256,8,256,8,9,144,3.2,72.0,1,15.6,10.91,0.009,26.56,37.65,1,677.71,5.42,5.42,0.009,0.004,IS,
76,An area-efficient 6T-SRAM based Compute-In-Memory architecture with reconfigurable SAR ADCs for energy efficient deep neural networks in edge ML applications,Avishek Biswas et al.,CICC,2022,45,SRAM,6T,16,256,64,0.8,6,2,6,1,16,64,64,16,32,12288,13.0,6144.0,1,40.00,153.60,0.31,504.00,1.984,4,1523.810,24.381,97.524,1.229,17.76,QS-QR,
77,"A 177 TOPS/W, Capacitor-based In-Memory Computing SRAM Macro with Stepwise-Charging/Discharging DACs and Sparsity-Optimized Bitcells for 4-Bit Deep Convolutional Neural Networks",Bo Zhang et al.,CICC,2022,28,SRAM,9T1C,16,128,128,0.8,2,4,6,128,128,4,4,32,128,65536,13.0,32768.0,2,72.80,450.11,0.90,2832.00,0.353,1,723.164,23.141,46.282,0.900,29.04,QR,
77,"A 177 TOPS/W, Capacitor-based In-Memory Computing SRAM Macro with Stepwise-Charging/Discharging DACs and Sparsity-Optimized Bitcells for 4-Bit Deep Convolutional Neural Networks",Bo Zhang et al.,CICC,2022,28,SRAM,9T1C,16,128,128,1,2,4,6,128,128,4,4,32,128,65536,13.0,32768.0,2,16.05,2041.62,4.08,2224.00,0.450,1,920.863,29.468,58.935,4.083,131.72,QR,
78,DCT-RAM: A Driver-Free Process-In-Memory 8T SRAM Macro with Multi-Bit Charge-Domain Computation and Time-Domain Quantization,Zhiyu Chen et al.,CICC,2022,65,SRAM,8T1C,73,576,128,0.8,4,1,8,576,576,1,1,128,576,589824,13.2,294912.0,1,40.00,7372.80,14.75,1288.00,0.776,1,3577.640,457.938,457.938,14.746,64.96,QR,
78,DCT-RAM: A Driver-Free Process-In-Memory 8T SRAM Macro with Multi-Bit Charge-Domain Computation and Time-Domain Quantization,Zhiyu Chen et al.,CICC,2022,65,SRAM,8T1C,73,576,128,1,4,1,8,576,576,1,1,128,576,589824,13.2,294912.0,1,25.00,11796.48,23.59,908.00,1.101,1,5074.890,649.586,649.586,23.593,103.93,QR,
79,A 133.6TOPS/W Compute-In-Memory SRAM Macro with Fully Parallel One-Step Multi-Bit Computation,Edward Choi et al.,CICC,2022,65,SRAM,8T1C,4,64,64,1.2,4,4,5,64,64,4,4,16,64,32768,14.0,16384.0,1,9.80,1671.84,3.34,837.28,1.194,1,2446.016,39.136,39.136,3.344,16.72,QR,
79,A 133.6TOPS/W Compute-In-Memory SRAM Macro with Fully Parallel One-Step Multi-Bit Computation,Edward Choi et al.,CICC,2022,65,SRAM,8T1C,4,64,64,0.85,4,4,5,64,64,4,4,16,64,32768,14.0,16384.0,1,15.60,1050.26,2.10,2137.28,0.468,1,958.227,15.332,15.332,2.101,10.50,QR,
80,T-PIM: A 2.21-to-161.08TOPS/W Processing-In-Memory Accelerator for End-to-End On-Device Training,Jaehoon Heo et al.,CICC,2022,28,SRAM,8T,219,288,256,0.75,1,2,,,,,,,,,,,1,3.57,,0.28,322.16,3.104,5,,,,1.400,0.82,,Y
81,"DDPMnet: All-Digital Pulse Density-Based DNN Architecture with 228 Gate Equivalents/MAC Unit, 28-TOPS/W and 1.5-TOPS/mm2 in 40nm",Animesh Gupta et al.,CICC,2022,40,Digital,Digital,113,,,0.5,3,3.81,,,,,,,,,,,,,,0.46,320.73,3.118,1,,,,0.457,1.18,,
82,A 17–95.6 TOPS/W Deep Learning Inference Accelerator with Per-Vector Scaled 4-bit Quantization for Transformers in 5nm,Ben Keller et al.,VLSI,2022,5,Digital,Digital,141,,,0.46,4,4,,,,,,,64,,14.0,,1,,,4.85,1529.60,0.654,1,1338.912,,,4.848,31.69,,
82,A 17–95.6 TOPS/W Deep Learning Inference Accelerator with Per-Vector Scaled 4-bit Quantization for Transformers in 5nm,Ben Keller et al.,VLSI,2022,5,Digital,Digital,141,,,1.05,4,4,,,,,,,64,,14.0,,1,,,57.60,288.00,3.472,1,7111.111,,,57.600,376.47,,
83,A 12nm 121-TOPS/W 41.6-TOPS/mm2 All Digital Full Precision SRAM-based Compute-in-Memory with Configurable Bit-width For AI Edge Applications,Chia-Fu Lee et al.,VLSI,2022,12,SRAM,6T+D,8,,,0.72,4,4,,,,,,,64,,14.0,,1,1.25,,21.49,1936.00,0.517,1,1057.851,,,21.488,665.26,,
84,Gain-Cell CIM: Leakage and Bitline Swing Aware 2T1C Gain-Cell eDRAM Compute in Memory Design with Bitline Precharge DACs and Compact Schmitt Trigger ADCs,Shanshan Xie et al.,VLSI,2022,65,eDRAM,2T1C,0.5,19,27,1,2,1,2,1,19,27,27,27,1,108,2.0,54.0,4,5,8.18,0.02,472.96,2.11,64,8.46,0.23,58.46,1.38,0.01,QS-QR,
85,An 8-bit 20.7 TOPS/W Multi-Level Cell ReRAM-based Compute Engine,Justin M. Correll et al.,VLSI,2022,65,eNVM,ReRAM+Cross,16,256,64,,8,4,8,256,256,1,2,32,256,524288,20.0,262144.0,1,143.00,1833.17,3.67,1324.80,0.755,4,12367.150,395.749,1582.995,14.665,16.90,IS,
87,A 22nm 128-kb MRAM Row/Column-Parallel In-Memory Computing Macro with Memory-Resistance Boosting and Multi-Column ADC Readout ,Peter Deaville et al.,VLSI,2022,22,eNVM,MRAM+Par,128,256,512,0.8,1,4,6,128,256,4,4,128,128,131072,11.0,65536.0,1,400.00,163.84,0.33,41.6,24.04,1,24615.38,3150.77,3150.77,0.33,2.41,IS,
89,A 32.2 TOPS/W SRAM Compute-in-Memory Macro Employing a Linear 8-bit C-2C Ladder for Charge Domain Computation in 22nm for Edge Inference,Hechen Wang et al.,VLSI,2022,22,SRAM,9T,64,512,128,1.1,8,8,8,64,256,8,8,16,64,131072,22.0,65536.0,1,4.17,15716.07,31.43,2060.80,0.485,2,3975.155,63.602,127.205,62.864,253.48,QR,
96,A 70.85-86.27-TOPS/W PVT-Insensitive 8b Word-Wise ACIM with Post Processing Relaxation,Sung-En Hsieh et al.,ISSCC,2023,12,SRAM,9T,8,256,32,0.85,8,4,8,64,32,1,256,1,64,4096,18.0,2048.0,1.0,9.77,209.72,0.42,4534.40,0.221,16.000,903.317,0.903,14.453,6.711,,QR,
133,A 2.38 MCells/mm2 9.81 - 350 TOPS/W RRAM Compute-in-Memory Macro in 40nm CMOS with Hybrid Offset/IOFF Cancellation and ICELLRBLSL Drop Mitigation,Samuel D. Spetalnick et al.,VLSI,2023,40,eNVM,1T1R,64,256,256,1.05,1,1,6,64,256,1,16,16,64,2048,6.0,1024.0,1,11.11,92.16,0.18,63.30,15.798,1,2022.117,32.354,32.354,0.184,7.01,IS,
136,A 12nm 137 TOPS/W Digital Compute-In-Memory Using Foundry 8T SRAM Bitcell Supporting 16 Kernel Weight Sets for AI Edge Applications,Gajanan Jedhe et al.,VLSI,2023,12,Digital,8T,4,512,128,0.55,1,4,,64,512,4,8,16,64,8192,10.0,4096.0,1.00,3.33,1228.80,2.46,2192.00,0.456,1.000,0.008,14.949,560.584,9.60,54.01,DIMC,
138,A General-Purpose Compute-in-Memory Processor Combining CPU and Deep Learning with Elevated CPU Efficiency and Enhanced Data Locality,Yuhao Ju et al.,VLSI,2023,65,SRAM,9T,1,32,32,1,8,8,,32,32,8,32,1,16,2048,20.0,1024.0,1,4.08,250.88,0.50,487.68,2.051,8,4199.48,4.20,0.07,4.01,2.09,DIMC,Y
139,A 5.6-89.9TOPS/W Heterogeneous Computing-in-Memory SoC with High-Utilization Producer-Consumer Architecture and High-Frequency Read-Free CIM Macro,Jinshan Yue et al,VLSI,2023,55,SRAM,6T,64,512,128,0.98,1,4,,128,128,1,32,16,128,16384,11.0,8192.0,2,2.00,4096.00,8.19,4176.00,0.239,16,245.21,3.92,0.50,131.07,77.28,DIMC,Y
102,TensorCIM: A 28nm 3.7nJ/Gather and 8.3TFLOPS/W FP32 Digital-CIM Tensor Processor for MCM-CIM-Based Beyond-NN Acceleration,Fengbin Tu et al.,ISSCC,2023,28,SRAM,6T,32,256,128,0.65,8,8,,16,256,32,128,1,64,8192,22.0,4096.0,1,5.71,716.80,1.43,1257.60,0.795,32,6513.99,6.51,208.45,45.88,13.78,DIMC,Y
108,A 73.53TOPS/W 14.74TOPS Heterogeneous RRAM In-Memory and SRAM Near-Memory SoC for Hybrid Frame and Event-Based Target Tracking,Muya Chang et al.,ISSCC,2023,40,eNVM,RRAM Parallel Bar,64,256,256,0.9,1,2,6,32,256,1,1,16,32,2048,7.0,1024.0,1,10.00,102.40,0.20,147.06,6.800,160,870.393,13.926,2228.206,32.768,0.01,IS,Y
110,"A 12.4TOPS/W @ 136GOPS AI-IoT System-on-Chip with 16 RISC-V, 2-to-8b Precision-Scalable DNN Acceleration and 30%-Boost Adaptive Body Biasing",Francesco Conti et al.,ISSCC,2023,22,Digital,,9216,,,0.8,,,,,,,,,,,,,,,,1.34,11.52,86.806,,,,,,,,
110,"A 12.4TOPS/W @ 136GOPS AI-IoT System-on-Chip with 16 RISC-V, 2-to-8b Precision-Scalable DNN Acceleration and 30%-Boost Adaptive Body Biasing",Francesco Conti et al.,ISSCC,2023,22,Digital,,9216,,,0.8,,,,,,,,,,,,,,,,1.34,51.2,19.531,,,,,,,,
110,"A 12.4TOPS/W @ 136GOPS AI-IoT System-on-Chip with 16 RISC-V, 2-to-8b Precision-Scalable DNN Acceleration and 30%-Boost Adaptive Body Biasing",Francesco Conti et al.,ISSCC,2023,22,Digital,,9216,,,0.8,,,,,,,,,,,,,,,,1.34,21.6,46.296,,,,,,,,
111,A 28nm 2D/3D Unified Sparse Convolution Accelerator with Block-Wise Neighbor Searcher for Large-Scaled Voxel-Based Point Cloud Network,Wenyu Sun et al.,ISSCC,2023,28,Digital,Digital,1408,,,0.48,,,,,,,,,,,,,,,,48.64,299.52,3.339,,,,,,,,
112,"A 127.8TOPS/W Arbitrarily Quantized 1-to-8b Scalable-Precision Accelerator for General-Purpose Deep Learning with Reduction of Storage, Logic and Latency Waste ",Seunghyun Moon et al.,ISSCC,2023,28,Digital,Digital,1600,,,0.46,,,,,,,,,,,,,,,,33.28,8179.20,0.122,,,,,,,,
112,"A 127.8TOPS/W Arbitrarily Quantized 1-to-8b Scalable-Precision Accelerator for General-Purpose Deep Learning with Reduction of Storage, Logic and Latency Waste ",Seunghyun Moon et al.,ISSCC,2023,28,Digital,Digital,1600,,,0.46,,,,,,,,,,,,,,,,336.64,572,1.748,,,,,,,,
118,"A 12nm 18.1TFLOPs/W Sparse Transformer Processor with Entropy-Based Early Exit, Mixed-Precision Predication and Fine-Grained Power Management",Tambe et. al.,ISSCC,2023,12,Digital,Digital,647,,,0.62,,,,,,,,,,,,,,,,11.74,289.60,3.453,,,,,,,,
119,"A 333TOPS/W Logic-Compatible Multi-Level Embedded
Flash Compute-In-Memory Macro with Dual-Slope Computation",Edward Choi et al.,CICC,2023,65,eFlash,6T+4FGT,6,64,32,0.75,1,3,6,64,64,32,32,32,64,12288,9.0,6144.0,4,12.50,491.52,0.98,3996.00,0.250,1,96.096,3.075,12.300,0.983,2.96,IS,
124,A Double-Mode Sparse Compute-In-Memory Macro with Reconfigurable Single and Dual Layer Computation,Yuanzhe Zhao et al.,CICC,2023,28,SRAM,8T1C,9,32,288,0.6,1,4,9,4,4,288,288,8,288,18432,12.2,9216.0,1,10.00,921.60,1.84,6582.80,0.152,1,350.00,2.80,2.80,1.84,19.61,,Y
128,AI Processor with Sparsity-adaptive Real-time Dynamic Frequency Modulation for Convolutional Neural Networks and Transformers,Yugandhar Khodke et al.,CICC,2023,65,Digital,Digital,0.5,32,16,1,8,8,,,,,,1,512,65536,25.0,32768.0,1,1.00,32768.00,65.54,38.40,26.042,1,1706666.67,1706.67,1706.67,65.54,16.79,,
150,Pianissimo: A Sub-mW Class DNN Accelerator with Progressive Bit-by-Bit Datapath Architecture for Adaptive Inference at Edge,Suzuki and Yu et al.,VLSI,2023,40,Digital,Digital,8832,,,0.7,8,1,,,,,,,,,,,,,,0.14,222.40,4.496,1,,,,0.145,0.02,,
91,A 28nm 64-kb 31.6-TFLOPS/W Digital-Domain Floating-Point- Computing-Unit and Double-Bit 6T-SRAM Computing-in- Memory Macro for Floating-Point CNNs,An Guo et al.,ISSCC,2023,28,SRAM,6T,64,512,128,0.6,2,2,,128,128,2,16,32,128,32768,11.0,16384.0,1,5.5,2978.91,5.96,2816,0.36,1,363.64,11.64,11.64,5.96,40.81,DIMC,
93,A 28nm 38-to-102-TOPS/W 8b Multiply-Less Approximate Digital SRAM Compute-In-Memory Macro for Neural-Network Inference,Yifan He et al.,ISSCC,2023,28,SRAM,8T,16,128,128,0.9,1,8,,128,128,1,8,16,128,32768,15.0,16384.0,1,4.35,3768.32,7.54,2432,0.41,1,842.11,13.47,13.47,7.54,269.17,DIMC,
94,A 4nm 6163-TOPS/W/b 4790-TOPS/mm2/b SRAM Based Digital-Computing-in-Memory Macro Supporting Bit-Width Flexibility and Simultaneous MAC and Weight Update,Hakuri Mori et al.,ISSCC,2023,4,SRAM,6T+D,54,288,192,0.9,1,12,,144,144,12,12,16,144,55296,19.2,27648.0,1,0.66,41890.91,83.78,1742.4,0.57,1,1983.47,31.74,31.74,83.78,4899.52,DIMC,
95,A 28-nm Horizontal-Weight-Shift and Vertical-Feature-Shift Based Separate-WL 6T-SRAM Computation-in-Memory Unit- Macro for Edge Depthwise Neural-Networks,Bo Wang et al.,ISSCC,2023,28,SRAM,6T,4.6,36,128,0.8,1,1,5,9,36,1,16,8,9,144,3.2,72.0,8,0.75,96.00,0.19,2140.16,0.47,2,8.41,0.07,1.08,0.38,32.00,QR,
130,A 28nm 1.07TFLOPS/mm2 Dynamic-Precision Training Processor with Online Dynamic Execution and Multi- Level-Aligned Block-FP Processing,Yixiong Yang et al.,CICC,2023,28,Digital,Digital,3424,,,1.14,2,2,,,,,,,,,,,,,,13.92,9.2,108.70,1,,,,13.92,4.30,,
128,AI Processor with Sparsity-adaptive Real-time Dynamic Frequency Modulation for Convolutional Neural Networks and Transformers,Yugandhar Khodke et al.,CICC,2023,65,Digital,Digital,0.5,32,16,1,8,8,,,,,,1,512,65536,25.0,32768.0,1,1.00,32768.00,65.54,38.40,26.042,1,1706666.67,1706.67,1706.67,65.54,16.79,,
132,A 26.55TOPS/W Explainable AI Processor with Dynamic Workload Allocation and Heat Map Compression/Pruning,Junsoo Kim et al,CICC,2023,28,Digital,Digital,256,,,0.74,16,16,,,,,,,,,,,,,,829.44,6796.80,0.147,1,,,,829.440,81.00,,
146,A 12-nm 0.62-1.61 mW Ultra-Low Power Digital CIM-Based Deep-Learning System for End-to-End Always-On Vision,Chang and Xue et al.,VLSI,2023,12,Digital,Digital,528,,,0.6,8,8,,,,,,,,,,,,,,3.28,2995.20,0.334,1,,,,3.277,1.86,,
147,A 28 nm 66.8 TOPS/W Sparsity-Aware Dynamic-Precision Deep-Learning Processor,Mun et al.,VLSI,2023,28,Digital,Digital,99.5,,,1.05,8,8,,,,,,,,,,,,,,66.88,561.92,1.780,4,,,,267.520,225.19,,
150,Pianissimo: A Sub-mW Class DNN Accelerator with Progressive Bit-by-Bit Datapath Architecture for Adaptive Inference at Edge,Suzuki and Yu et al.,VLSI,2023,40,Digital,Digital,8832,,,0.7,8,1,,,,,,,,,,,,,,0.14,222.40,4.496,1,,,,0.145,0.02,,
151,A 28nm 77.35TOPS/W Similar Vectors Traceable Transformer Processor with Principal-Component-Prior Speculating and Dynamic Bit-Wise Stationary Computing,Wang et al.,VLSI,2023,28,Digital,Digital,60,,,0.71,8,8,,,,,,,,,,,,,,92.82,4950.40,0.202,8,,,,742.560,322.29,,
151,A 28nm 77.35TOPS/W Similar Vectors Traceable Transformer Processor with Principal-Component-Prior Speculating and Dynamic Bit-Wise Stationary Computing,Wang et al.,VLSI,2023,28,Digital,Digital,60,,,1,8,8,,,,,,,,,,,,,,118.56,2371.2,0.4217273954,8,,,,948.480,411.67,,